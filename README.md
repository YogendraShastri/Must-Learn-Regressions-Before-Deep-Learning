# Must-Learn-Regressions-Before-Deep-Learning
**lets see major regression before starting with deep learning and neural networks**

Here's a list of regressions you should definitely learn. 
- Linear Regression
- Multiple Linear Regression
- Polynomial Regression
- Logistic Regression
- Bayesian Regression

Optional :
- Ridge & Lasso Regression
- Elastic Net Regression
- Quantile Regression

## What is Linear Regression
We all know the general equation of a straight line is y = mx + c, where m is the slope of the line and c is the y-intercept. So when we talk about linear regression, what we are doing is trying to draw a line that best fits the data, so we can make predictions or understand the relationship between variables.
It might sound a bit confusing, but in linear regression, we try to find a linear relationship between an independent variable (x) and a dependent variable (y).
one more thing **Linear regression** is a type of supervised machine-learning algorithm.

### Equation (Simple Linear Regression)

The equation for **Simple Linear Regression** is:

$$
y = w \cdot x + b
$$

### Where:
- **y** = Predicted value (dependent variable)  
- **x** = Input feature (independent variable)  
- **w** = Weight (slope of the line)  
- **b** = Bias (intercept)

You're trying to find the best w and b that make your predictions match the actual values.






